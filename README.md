# AI-Powered Emotion Recognition System

**Author:** Anuroop Arya
## Overview

Engineered an advanced emotion recognition system using Convolutional Neural Networks (CNNs) to classify facial expressions into seven categories. Leveraged deep learning libraries such as Keras for model building and optimization. Trained on a dataset of 28,821 images with extensive data augmentation techniques. Employed optimization algorithms including Adam, SGD, and RMSprop to enhance model accuracy, achieving a 70% accuracy rate. Utilized Matplotlib, Seaborn, and Pandas for data visualization and analysis. This project demonstrates the application of state-of-the-art technologies in Human-Computer Interaction (HCI), enhancing user experience through precise emotion detection

## Technologies Used

- **Deep Learning Libraries**: Keras, TensorFlow
- **Data Augmentation**: Applied techniques to improve model robustness
- **Optimization Algorithms**: Adam, SGD, RMSprop
- **Data Visualization**: Matplotlib, Seaborn, Pandas
- **Computer Vision**: OpenCV
- **Programming Languages**: Python

## Getting Started

### Prerequisites

Ensure you have the following Python packages installed:

- Keras
- TensorFlow
- OpenCV
- NumPy

You can install the required packages using pip:

```bash
pip install keras tensorflow opencv-python numpy
```
## How It Works
Face Detection: The script uses Haar Cascades to detect faces in real-time video frames.
Emotion Classification: Detected face regions are preprocessed and classified using the pre-trained CNN model.
Display: Emotion labels are overlaid on the video feed, indicating the detected emotion.

## Contributing
Feel free to fork this repository and submit pull requests. For any issues or improvements, please open an issue in the project's GitHub repository.

 ```bash
   git clone https://github.com/mylifeasAnuroop/FaceInsight-AI-Powered-Emotion-Recognition-for-User-Experience
   cd FaceInsight-AI-Powered-Emotion-Recognition-for-User-Experience
 ```

## Real-World Applications

- **Museums and Exhibitions**: Guide visitors to exhibits based on their detected emotions to enhance their experience.
- **Retail**: Personalize shopping experiences by understanding customer emotions.
- **Healthcare**: Assist in mental health analysis by detecting patient emotions.
- **Human-Computer Interaction**: Improve interaction by understanding user emotions.

